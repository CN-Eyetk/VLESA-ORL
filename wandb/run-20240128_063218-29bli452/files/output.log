/disk/junlin/EmoSp/bart-our/-LIGHT-TRANS4/all_loss0.6_0.2_0.2_kl-lr_2e-05-Situ-Emoin-nopp-empp-no_fuse-bart-eosemo-role-emocat-stgcat-vae-mvae256-wo_comet-vad-frz_stem124_II
vocab size = 50265
10192 10192 10192

















































































































 22%|████████████████████████████▎                                                                                                  | 2269/10191 [03:47<13:15,  9.95it/s]
Traceback (most recent call last):
  File "/home/lijunlin/lijunlin/ESCONV/main.py", line 316, in <module>
    train_dataset, eval_dataset, test_dataset = load_dataset(args, tokenizer)
  File "/home/lijunlin/lijunlin/ESCONV/main.py", line 279, in load_dataset
    train_dataset = load_and_cache_examples(args, tokenizer, df_trn, comet_trn, st_comet_trn, evaluate=False, strategy=args.strategy, situations = st_trn)
  File "/home/lijunlin/lijunlin/ESCONV/BlenderEmotionalSupport.py", line 1011, in load_and_cache_examples
    return ESDDataset(tokenizer, args, df, comet, comet_st, evaluate=evaluate, strategy=strategy, test=test, situations = situations, vad_tokenizer = vad_tokenizer)
  File "/home/lijunlin/lijunlin/ESCONV/BlenderEmotionalSupport.py", line 777, in __init__
    conv = construct_conv_ESD(args, idx, row, comet_row, comet_st_row, tokenizer, cls=False, strategy=strategy ,evaluate=evaluate, situation = situations[idx], prepend_emotion = args.prepend_emotion, use_emo_in_dist = args.use_emo_in_dist, vad_tokenizer = vad_tokenizer)
  File "/home/lijunlin/lijunlin/ESCONV/BlenderEmotionalSupport.py", line 708, in construct_conv_ESD
    inputs, roles, turns, strategy_labels, _, _, emo_in_dist, _, vad_ids= _get_inputs_from_text("EOS".join(row.split("EOS")[:-1]), tokenizer, strategy=strategy, get_emo_dist = False, get_emo_in_dist = (True if use_emo_in_dist else False),
  File "/home/lijunlin/lijunlin/ESCONV/BlenderEmotionalSupport.py", line 649, in _get_inputs_from_text
    context_id_new, tokens, vad_labels = vad_tokenizer.tokenizer_vad(vad_input
  File "/home/lijunlin/lijunlin/ESCONV/attach_vad/VADTokenizer.py", line 147, in tokenizer_vad
    vad_token = [nlp_vad[k][-1] for k in offsets]
  File "/home/lijunlin/lijunlin/ESCONV/attach_vad/VADTokenizer.py", line 147, in <listcomp>
    vad_token = [nlp_vad[k][-1] for k in offsets]
IndexError: list index out of range