/disk/junlin/EmoSp/bart-our/-LIGHT-TRANS4/all_loss0.6_0.2_0.2_kl-lr_2e-05-Emoin-nopp-empp-ensitu-desitu-vae-mvae256-wo_comet-vad124_II
vocab size = 50265
Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['encoder.layers.0.attn_layer_norm_comet.weight', 'encoder.layers.0.attn_layer_norm_comet.bias', 'encoder.layers.1.attn_layer_norm_comet.weight', 'encoder.layers.1.attn_layer_norm_comet.bias', 'encoder.layers.2.attn_layer_norm_comet.weight', 'encoder.layers.2.attn_layer_norm_comet.bias', 'encoder.layers.3.attn_layer_norm_comet.weight', 'encoder.layers.3.attn_layer_norm_comet.bias', 'encoder.layers.4.attn_layer_norm_comet.weight', 'encoder.layers.4.attn_layer_norm_comet.bias', 'encoder.layers.5.attn_layer_norm_comet.weight', 'encoder.layers.5.attn_layer_norm_comet.bias', 'encoder.layers.5.muAttn.k_proj.weight', 'encoder.layers.5.muAttn.k_proj.bias', 'encoder.layers.5.muAttn.v_proj.weight', 'encoder.layers.5.muAttn.v_proj.bias', 'encoder.layers.5.muAttn.q_proj.weight', 'encoder.layers.5.muAttn.q_proj.bias', 'encoder.layers.5.muAttn.out_proj.weight', 'encoder.layers.5.muAttn.out_proj.bias', 'encoder.emotion_head.weight', 'encoder.emotion_head.bias', 'encoder.batchNorm_emotion.weight', 'encoder.batchNorm_emotion.bias', 'encoder.batchNorm_emotion.running_mean', 'encoder.batchNorm_emotion.running_var', 'encoder.batchNorm_strategy.weight', 'encoder.batchNorm_strategy.bias', 'encoder.batchNorm_strategy.running_mean', 'encoder.batchNorm_strategy.running_var', 'encoder.strategy_embedding.weight', 'encoder.multi_state_LayerNorm.weight', 'encoder.multi_state_LayerNorm.bias', 'encoder.strategy_head.weight', 'encoder.strategy_head.bias', 'encoder.trans_mat.emotion_embedding.weight', 'encoder.trans_mat.h_prior_emo.weight', 'encoder.trans_mat.h_prior_emo.bias', 'encoder.trans_mat.h_prior_strat.weight', 'encoder.trans_mat.h_prior_strat.bias', 'encoder.trans_mat.mu_prior.weight', 'encoder.trans_mat.mu_prior.bias', 'encoder.trans_mat.logvar_prior.weight', 'encoder.trans_mat.logvar_prior.bias', 'encoder.trans_mat.Dense_z_prior.weight', 'encoder.trans_mat.Dense_z_prior.bias', 'encoder.trans_mat.h_posterior_emo.weight', 'encoder.trans_mat.h_posterior_emo.bias', 'encoder.trans_mat.h_posterior_strat.weight', 'encoder.trans_mat.h_posterior_strat.bias', 'encoder.trans_mat.mu_posterior.weight', 'encoder.trans_mat.mu_posterior.bias', 'encoder.trans_mat.logvar_posterior.weight', 'encoder.trans_mat.logvar_posterior.bias', 'encoder.strat_cat_attn.V', 'encoder.strat_cat_attn.W.weight', 'encoder.emo_cat_attn.V', 'encoder.emo_cat_attn.W.weight', 'decoder.layers.0.encoder_attn_layer_norm_strategy.weight', 'decoder.layers.0.encoder_attn_layer_norm_strategy.bias', 'decoder.layers.0.encoder_attn_layer_norm_comet.weight', 'decoder.layers.0.encoder_attn_layer_norm_comet.bias', 'decoder.layers.0.encoder_attn_layer_norm_total.weight', 'decoder.layers.0.encoder_attn_layer_norm_total.bias', 'decoder.layers.1.encoder_attn_layer_norm_strategy.weight', 'decoder.layers.1.encoder_attn_layer_norm_strategy.bias', 'decoder.layers.1.encoder_attn_layer_norm_comet.weight', 'decoder.layers.1.encoder_attn_layer_norm_comet.bias', 'decoder.layers.1.encoder_attn_layer_norm_total.weight', 'decoder.layers.1.encoder_attn_layer_norm_total.bias', 'decoder.layers.2.encoder_attn_layer_norm_strategy.weight', 'decoder.layers.2.encoder_attn_layer_norm_strategy.bias', 'decoder.layers.2.encoder_attn_layer_norm_comet.weight', 'decoder.layers.2.encoder_attn_layer_norm_comet.bias', 'decoder.layers.2.encoder_attn_layer_norm_total.weight', 'decoder.layers.2.encoder_attn_layer_norm_total.bias', 'decoder.layers.3.encoder_attn_layer_norm_strategy.weight', 'decoder.layers.3.encoder_attn_layer_norm_strategy.bias', 'decoder.layers.3.encoder_attn_layer_norm_comet.weight', 'decoder.layers.3.encoder_attn_layer_norm_comet.bias', 'decoder.layers.3.encoder_attn_layer_norm_total.weight', 'decoder.layers.3.encoder_attn_layer_norm_total.bias', 'decoder.layers.4.encoder_attn_layer_norm_strategy.weight', 'decoder.layers.4.encoder_attn_layer_norm_strategy.bias', 'decoder.layers.4.encoder_attn_layer_norm_comet.weight', 'decoder.layers.4.encoder_attn_layer_norm_comet.bias', 'decoder.layers.4.encoder_attn_layer_norm_total.weight', 'decoder.layers.4.encoder_attn_layer_norm_total.bias', 'decoder.layers.5.encoder_attn_layer_norm_strategy.weight', 'decoder.layers.5.encoder_attn_layer_norm_strategy.bias', 'decoder.layers.5.encoder_attn_layer_norm_comet.weight', 'decoder.layers.5.encoder_attn_layer_norm_comet.bias', 'decoder.layers.5.encoder_attn_layer_norm_total.weight', 'decoder.layers.5.encoder_attn_layer_norm_total.bias', 'fuse_st_emo.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|                                                                                                                 | 0/510 [00:00<?, ?it/s]
without comet
BartConfig {
  "_name_or_path": "facebook/bart-base",
  "activation_dropout": 0.1,
  "activation_function": "gelu",
  "add_bias_logits": false,
  "add_emo_cross_attn": false,
  "add_final_layer_norm": false,
  "architectures": [
    "BartModel"
  ],
  "attention_dropout": 0.1,
  "bos_token_id": 0,
  "classif_dropout": 0.1,
  "classifier_dropout": 0.0,
  "d_model": 768,
  "decoder_attention_heads": 12,
  "decoder_ffn_dim": 3072,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 6,
  "decoder_start_token_id": 2,
  "dropout": 0.1,
  "early_stopping": true,
  "emo_from_eos": true,
  "emo_from_situ": false,
  "emo_loss_ratio": 0.2,
  "emo_out_loss_ratio": 0.2,
  "emo_use_cat_attn": true,
  "encoder_attention_heads": 12,
  "encoder_ffn_dim": 3072,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 6,
  "eos_token_id": 2,
  "force_bos_token_to_be_generated": false,
  "forced_bos_token_id": 0,
  "forced_eos_token_id": 2,
  "gradient_checkpointing": false,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "init_std": 0.02,
  "intensity_vae": false,
  "is_encoder_decoder": true,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "latent_dim": 256,
  "lstm_st_seq": false,
  "max_position_embeddings": 1024,
  "merge": false,
  "mixed_vae": true,
  "model_type": "bart",
  "n_emo_out": 28,
  "no_fuse": true,
  "no_repeat_ngram_size": 3,
  "normalize_before": false,
  "normalize_embedding": true,
  "num_beams": 4,
  "num_hidden_layers": 6,
  "pad_token_id": 1,
  "prepend": false,
  "rl_emb_ratio": 0.6,
  "sample_strat_emb": false,
  "scale_embedding": false,
  "st_from_eos": true,
  "stg_use_cat_attn": true,
  "task_specific_params": {
    "summarization": {
      "length_penalty": 1.0,
      "max_length": 128,
      "min_length": 12,
      "num_beams": 4
    },
    "summarization_cnn": {
      "length_penalty": 2.0,
      "max_length": 142,
      "min_length": 56,
      "num_beams": 4
    },
    "summarization_xsum": {
      "length_penalty": 1.0,
      "max_length": 62,
      "min_length": 11,
      "num_beams": 6
    }
  },
  "torch_dtype": "float32",
  "transformers_version": "4.2.2",
  "use_cache": true,
  "use_copy": false,
  "use_emb_prep": true,
  "use_emo_in_dist": true,
  "use_kl": true,
  "use_role_embed": true,
  "use_situ_in_decoder": true,
  "use_situ_in_encoder": true,
  "use_st_seq": false,
  "use_th_attn": false,
  "use_trans_mat": true,
  "use_vad_labels": true,
  "use_vae": true,
  "vad_emb_ratio": 0.2,
  "vocab_size": 50265,
  "wo_comet": true,
  "wo_emo": false,
  "wo_stra": false
}
args.local_rank =  -1
162,803,592 total parameters.
162,803,592 training parameters.
contrast_loss tensor(2.8113, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.9328, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6598, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(5.1448, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(3.0397, device='cuda:0', grad_fn=<MeanBackward0>)

  0%|▍                                                                                                        | 2/510 [00:01<06:43,  1.26it/s]
contrast_loss tensor(2.8043, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(5.0213, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7964, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.8551, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6280, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(5.0389, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5046, device='cuda:0', grad_fn=<MeanBackward0>)

  1%|█▏                                                                                                       | 6/510 [00:03<04:59,  1.69it/s]
contrast_loss tensor(2.6631, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.9593, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7891, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.8622, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9580, device='cuda:0', grad_fn=<MeanBackward0>)

  2%|██                                                                                                      | 10/510 [00:06<04:43,  1.77it/s]
contrast_loss tensor(2.9311, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.7637, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.4907, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.8141, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6393, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.6880, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6343, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.8540, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7963, device='cuda:0', grad_fn=<MeanBackward0>)


  4%|███▊                                                                                                    | 19/510 [00:10<03:46,  2.17it/s]
contrast_loss tensor(2.6646, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.8529, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9558, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.6464, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5218, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.7930, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9464, device='cuda:0', grad_fn=<MeanBackward0>)

  5%|████▋                                                                                                   | 23/510 [00:11<03:36,  2.25it/s]
contrast_loss tensor(2.8067, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.3954, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6558, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.1546, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5381, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.5839, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8027, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.3650, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6458, device='cuda:0', grad_fn=<MeanBackward0>)

  5%|█████▋                                                                                                  | 28/510 [00:14<03:30,  2.29it/s]
contrast_loss tensor(2.6556, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.1103, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.3862, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.0394, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8044, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.9563, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6432, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.0630, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6546, device='cuda:0', grad_fn=<MeanBackward0>)

  6%|██████▌                                                                                                 | 32/510 [00:15<03:35,  2.22it/s]
contrast_loss tensor(2.9402, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.8540, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6603, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.9734, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9517, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.1277, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6649, device='cuda:0', grad_fn=<MeanBackward0>)

  7%|███████▌                                                                                                | 37/510 [00:18<03:26,  2.29it/s]
contrast_loss tensor(2.6443, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.3546, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9491, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5793, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6472, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.1400, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8021, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.1193, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5292, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.9538, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9924, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.7887, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5203, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.0108, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6463, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(4.0375, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6538, device='cuda:0', grad_fn=<MeanBackward0>)


  9%|█████████▍                                                                                              | 46/510 [00:22<03:38,  2.12it/s]
contrast_loss tensor(2.9425, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6727, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8119, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.8340, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5293, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5600, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8049, device='cuda:0', grad_fn=<MeanBackward0>)

 10%|██████████▏                                                                                             | 50/510 [00:24<03:37,  2.12it/s]
contrast_loss tensor(2.8169, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6881, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5201, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.7260, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5022, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4666, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8051, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6744, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9580, device='cuda:0', grad_fn=<MeanBackward0>)

 11%|███████████▏                                                                                            | 55/510 [00:26<03:19,  2.28it/s]
contrast_loss tensor(2.9504, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6241, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6597, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.7386, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8005, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5822, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8873, device='cuda:0', grad_fn=<MeanBackward0>)

 12%|████████████                                                                                            | 59/510 [00:28<03:19,  2.26it/s]
contrast_loss tensor(2.7960, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4026, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7972, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5113, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5092, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4916, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8151, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3786, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9697, device='cuda:0', grad_fn=<MeanBackward0>)

 12%|████████████▊                                                                                           | 63/510 [00:29<03:11,  2.33it/s]
contrast_loss tensor(2.7960, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3132, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7630, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5087, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6606, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4894, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5183, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5791, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5021, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5260, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8317, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6163, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6718, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6328, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.4943, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3752, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7969, device='cuda:0', grad_fn=<MeanBackward0>)

 13%|█████████████▊                                                                                          | 68/510 [00:32<03:20,  2.21it/s]
contrast_loss tensor(2.9335, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3221, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8138, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.7837, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8057, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5061, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5207, device='cuda:0', grad_fn=<MeanBackward0>)


 15%|███████████████▋                                                                                        | 77/510 [00:36<03:21,  2.14it/s]
contrast_loss tensor(2.4856, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3577, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9528, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4803, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6793, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(2.9661, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6627, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3451, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8098, device='cuda:0', grad_fn=<MeanBackward0>)

 16%|████████████████▌                                                                                       | 81/510 [00:38<03:09,  2.26it/s]
contrast_loss tensor(2.7911, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5249, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8078, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2204, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6487, device='cuda:0', grad_fn=<MeanBackward0>)

 17%|█████████████████▎                                                                                      | 85/510 [00:39<03:22,  2.10it/s]
contrast_loss tensor(2.6651, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3174, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9514, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2862, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5162, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2643, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.4951, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.5447, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6497, device='cuda:0', grad_fn=<MeanBackward0>)

 17%|██████████████████▏                                                                                     | 89/510 [00:41<03:18,  2.12it/s]
contrast_loss tensor(2.8973, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4079, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5092, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4594, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5310, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3886, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7377, device='cuda:0', grad_fn=<MeanBackward0>)

 18%|███████████████████▏                                                                                    | 94/510 [00:44<03:04,  2.26it/s]
contrast_loss tensor(2.4988, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.1120, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.6725, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3053, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.3730, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.1327, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5101, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4641, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8214, device='cuda:0', grad_fn=<MeanBackward0>)

 19%|████████████████████▏                                                                                   | 99/510 [00:46<03:01,  2.27it/s]
contrast_loss tensor(2.8022, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2457, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8036, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.7077, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.5267, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2804, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.7994, device='cuda:0', grad_fn=<MeanBackward0>)

 20%|████████████████████▊                                                                                  | 103/510 [00:48<03:12,  2.12it/s]
contrast_loss tensor(2.6593, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4981, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8178, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2901, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8035, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.2844, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.3838, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.3293, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.2403, device='cuda:0', grad_fn=<MeanBackward0>)

 21%|█████████████████████▌                                                                                 | 107/510 [00:49<03:08,  2.14it/s]
contrast_loss tensor(2.7625, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.4197, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.9568, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.6023, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(2.8019, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(3.1571, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)

 22%|██████████████████████▌                                                                                | 112/510 [00:52<03:04,  2.15it/s]
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)

 23%|███████████████████████▍                                                                               | 116/510 [00:54<02:59,  2.19it/s]
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)
masked_lm_loss tensor(nan, device='cuda:0', grad_fn=<NllLossBackward0>)
contrast_loss tensor(nan, device='cuda:0', grad_fn=<MeanBackward0>)

